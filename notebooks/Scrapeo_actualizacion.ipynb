{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>url</th>\n",
       "      <th>Image 1 URL</th>\n",
       "      <th>Image 2 URL</th>\n",
       "      <th>current_price_x</th>\n",
       "      <th>description</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>old_price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>current_price_y</th>\n",
       "      <th>color</th>\n",
       "      <th>image_url</th>\n",
       "      <th>mpn</th>\n",
       "      <th>reference_code</th>\n",
       "      <th>category_id</th>\n",
       "      <th>Stock Status</th>\n",
       "      <th>color_homogeneizado</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Camiseta Sakamoto Store</td>\n",
       "      <td>https://www.pullandbear.com/es/camiseta-sakamo...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/8...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/c...</td>\n",
       "      <td>17.99</td>\n",
       "      <td>Camiseta blanca licencia Sakamoto con gráfico,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.99</td>\n",
       "      <td>Blanco roto</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/0...</td>\n",
       "      <td>3245/539</td>\n",
       "      <td>3245539.0</td>\n",
       "      <td>1.030140e+09</td>\n",
       "      <td>In Stock</td>\n",
       "      <td>Blanco</td>\n",
       "      <td>Camiseta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Camiseta negra Sakamoto</td>\n",
       "      <td>https://www.pullandbear.com/es/camiseta-negra-...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/5...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/c...</td>\n",
       "      <td>17.99</td>\n",
       "      <td>Camiseta licencia Sakamoto de color negro con ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.99</td>\n",
       "      <td>Negro</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/8...</td>\n",
       "      <td>3245/918</td>\n",
       "      <td>3245918.0</td>\n",
       "      <td>1.030140e+09</td>\n",
       "      <td>In Stock</td>\n",
       "      <td>Negro</td>\n",
       "      <td>Camiseta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Camiseta Sakamoto Ramen</td>\n",
       "      <td>https://www.pullandbear.com/es/camiseta-sakamo...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/2...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/b...</td>\n",
       "      <td>17.99</td>\n",
       "      <td>Camiseta licencia Sakamoto de color blanco con...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.99</td>\n",
       "      <td>Blanco roto</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/7...</td>\n",
       "      <td>3245/919</td>\n",
       "      <td>3245919.0</td>\n",
       "      <td>1.030140e+09</td>\n",
       "      <td>In Stock</td>\n",
       "      <td>Blanco</td>\n",
       "      <td>Camiseta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Camiseta Honda</td>\n",
       "      <td>https://www.pullandbear.com/es/camiseta-honda-...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/f...</td>\n",
       "      <td>https://static.pullandbear.net/2/photos//2025/...</td>\n",
       "      <td>15.99</td>\n",
       "      <td>Camiseta de manga corta blanca y cuello redond...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.99</td>\n",
       "      <td>Blanco</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/7...</td>\n",
       "      <td>3245/519</td>\n",
       "      <td>3245519.0</td>\n",
       "      <td>1.030140e+09</td>\n",
       "      <td>In Stock</td>\n",
       "      <td>Blanco</td>\n",
       "      <td>Camiseta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Camiseta básica muscle fit</td>\n",
       "      <td>https://www.pullandbear.com/es/camiseta-basica...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/3...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/5...</td>\n",
       "      <td>7.99</td>\n",
       "      <td>MUSCLE FIT. Camiseta básica de manga corta, co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.99</td>\n",
       "      <td>Negro</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/0...</td>\n",
       "      <td>3245/502</td>\n",
       "      <td>3245502.0</td>\n",
       "      <td>1.030205e+09</td>\n",
       "      <td>In Stock</td>\n",
       "      <td>Negro</td>\n",
       "      <td>Camiseta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Product Name  \\\n",
       "0     Camiseta Sakamoto Store   \n",
       "1     Camiseta negra Sakamoto   \n",
       "2     Camiseta Sakamoto Ramen   \n",
       "3              Camiseta Honda   \n",
       "4  Camiseta básica muscle fit   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.pullandbear.com/es/camiseta-sakamo...   \n",
       "1  https://www.pullandbear.com/es/camiseta-negra-...   \n",
       "2  https://www.pullandbear.com/es/camiseta-sakamo...   \n",
       "3  https://www.pullandbear.com/es/camiseta-honda-...   \n",
       "4  https://www.pullandbear.com/es/camiseta-basica...   \n",
       "\n",
       "                                         Image 1 URL  \\\n",
       "0  https://static.pullandbear.net/assets/public/8...   \n",
       "1  https://static.pullandbear.net/assets/public/5...   \n",
       "2  https://static.pullandbear.net/assets/public/2...   \n",
       "3  https://static.pullandbear.net/assets/public/f...   \n",
       "4  https://static.pullandbear.net/assets/public/3...   \n",
       "\n",
       "                                         Image 2 URL  current_price_x  \\\n",
       "0  https://static.pullandbear.net/assets/public/c...            17.99   \n",
       "1  https://static.pullandbear.net/assets/public/c...            17.99   \n",
       "2  https://static.pullandbear.net/assets/public/b...            17.99   \n",
       "3  https://static.pullandbear.net/2/photos//2025/...            15.99   \n",
       "4  https://static.pullandbear.net/assets/public/5...             7.99   \n",
       "\n",
       "                                         description  sale_price  old_price  \\\n",
       "0  Camiseta blanca licencia Sakamoto con gráfico,...         NaN        NaN   \n",
       "1  Camiseta licencia Sakamoto de color negro con ...         NaN        NaN   \n",
       "2  Camiseta licencia Sakamoto de color blanco con...         NaN        NaN   \n",
       "3  Camiseta de manga corta blanca y cuello redond...         NaN        NaN   \n",
       "4  MUSCLE FIT. Camiseta básica de manga corta, co...         NaN        NaN   \n",
       "\n",
       "   original_price  current_price_y        color  \\\n",
       "0             NaN            17.99  Blanco roto   \n",
       "1             NaN            17.99        Negro   \n",
       "2             NaN            17.99  Blanco roto   \n",
       "3             NaN            15.99       Blanco   \n",
       "4             NaN             7.99        Negro   \n",
       "\n",
       "                                           image_url       mpn  \\\n",
       "0  https://static.pullandbear.net/assets/public/0...  3245/539   \n",
       "1  https://static.pullandbear.net/assets/public/8...  3245/918   \n",
       "2  https://static.pullandbear.net/assets/public/7...  3245/919   \n",
       "3  https://static.pullandbear.net/assets/public/7...  3245/519   \n",
       "4  https://static.pullandbear.net/assets/public/0...  3245/502   \n",
       "\n",
       "   reference_code   category_id Stock Status color_homogeneizado Categoria  \n",
       "0       3245539.0  1.030140e+09     In Stock              Blanco  Camiseta  \n",
       "1       3245918.0  1.030140e+09     In Stock               Negro  Camiseta  \n",
       "2       3245919.0  1.030140e+09     In Stock              Blanco  Camiseta  \n",
       "3       3245519.0  1.030140e+09     In Stock              Blanco  Camiseta  \n",
       "4       3245502.0  1.030205e+09     In Stock               Negro  Camiseta  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer el archivo CSV\n",
    "df_base = pd.read_csv(\"../results/all_products_info_with_categories.csv\")\n",
    "\n",
    "print(df_base.shape)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cookies aceptadas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:36<06:38, 36.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_ropa_camisetas-n6323.html\n",
      "Se han encontrado 142 productos\n",
      "No se encontró el botón de cookies o ya estaba aceptado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:51<03:56, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_rebajas_ropa_camisetas-y-polos-n7087.html\n",
      "Se han encontrado 46 productos\n",
      "No se encontró el botón de cookies o ya estaba aceptado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [01:14<03:33, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_ropa_camisas-n6313.html\n",
      "Se han encontrado 85 productos\n",
      "No se encontró el botón de cookies o ya estaba aceptado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [01:35<03:00, 22.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_rebajas_ropa_camisas-n7088.html\n",
      "Se han encontrado 70 productos\n",
      "No se encontró el botón de cookies o ya estaba aceptado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [01:52<02:22, 20.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_ropa_punto-n6372.html\n",
      "Se han encontrado 54 productos\n",
      "No se encontró el botón de cookies o ya estaba aceptado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [02:06<01:49, 18.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_rebajas_ropa_punto-n7090.html\n",
      "Se han encontrado 36 productos\n",
      "No se encontró el botón de cookies o ya estaba aceptado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [02:47<02:08, 25.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_ropa_sudaderas-n6382.html\n",
      "Se han encontrado 179 productos\n",
      "No se encontró el botón de cookies o ya estaba aceptado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [03:01<01:27, 21.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_rebajas_ropa_sudaderas-n7089.html\n",
      "Se han encontrado 39 productos\n",
      "No se encontró el botón de cookies o ya estaba aceptado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [03:28<01:10, 23.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_ropa_pantalones-n6363.html\n",
      "Se han encontrado 112 productos\n",
      "No se encontró el botón de cookies o ya estaba aceptado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [03:47<00:44, 22.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_rebajas_ropa_pantalones-n7091.html\n",
      "Se han encontrado 67 productos\n",
      "No se encontró el botón de cookies o ya estaba aceptado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [04:17<00:24, 24.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_ropa_jeans-n6347.html\n",
      "Se han encontrado 114 productos\n",
      "No se encontró el botón de cookies o ya estaba aceptado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [04:32<00:00, 22.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML extraído correctamente y guardado como pagina_pullandbear_https___www.pullandbear.com_es_hombre_rebajas_ropa_jeans-n7818.html\n",
      "Se han encontrado 49 productos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articulos base:\n",
      "(887, 18)\n",
      "Articulos actuales:\n",
      "(993, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>url</th>\n",
       "      <th>Image 1 URL</th>\n",
       "      <th>Image 2 URL</th>\n",
       "      <th>current_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Camiseta Sakamoto Store</td>\n",
       "      <td>https://www.pullandbear.com/es/camiseta-sakamo...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/8...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/c...</td>\n",
       "      <td>17.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Camiseta Peanuts blanca</td>\n",
       "      <td>https://www.pullandbear.com/es/camiseta-peanut...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/7...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/d...</td>\n",
       "      <td>15.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polo Peanuts rayas</td>\n",
       "      <td>https://www.pullandbear.com/es/polo-peanuts-ra...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/0...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/b...</td>\n",
       "      <td>22.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Camiseta Peanuts verde</td>\n",
       "      <td>https://www.pullandbear.com/es/camiseta-peanut...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/3...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/4...</td>\n",
       "      <td>15.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Camiseta negra Mona Lisa</td>\n",
       "      <td>https://www.pullandbear.com/es/camiseta-negra-...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/a...</td>\n",
       "      <td>https://static.pullandbear.net/assets/public/0...</td>\n",
       "      <td>15.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Product Name  \\\n",
       "0   Camiseta Sakamoto Store   \n",
       "1   Camiseta Peanuts blanca   \n",
       "2        Polo Peanuts rayas   \n",
       "3    Camiseta Peanuts verde   \n",
       "4  Camiseta negra Mona Lisa   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.pullandbear.com/es/camiseta-sakamo...   \n",
       "1  https://www.pullandbear.com/es/camiseta-peanut...   \n",
       "2  https://www.pullandbear.com/es/polo-peanuts-ra...   \n",
       "3  https://www.pullandbear.com/es/camiseta-peanut...   \n",
       "4  https://www.pullandbear.com/es/camiseta-negra-...   \n",
       "\n",
       "                                         Image 1 URL  \\\n",
       "0  https://static.pullandbear.net/assets/public/8...   \n",
       "1  https://static.pullandbear.net/assets/public/7...   \n",
       "2  https://static.pullandbear.net/assets/public/0...   \n",
       "3  https://static.pullandbear.net/assets/public/3...   \n",
       "4  https://static.pullandbear.net/assets/public/a...   \n",
       "\n",
       "                                         Image 2 URL  current_price  \n",
       "0  https://static.pullandbear.net/assets/public/c...          17.99  \n",
       "1  https://static.pullandbear.net/assets/public/d...          15.99  \n",
       "2  https://static.pullandbear.net/assets/public/b...          22.99  \n",
       "3  https://static.pullandbear.net/assets/public/4...          15.99  \n",
       "4  https://static.pullandbear.net/assets/public/0...          15.99  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_url(url, driver):\n",
    "    result = None\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # Esperar a que la página cargue\n",
    "\n",
    "        # Aceptar cookies\n",
    "        try:\n",
    "            boton_cookies = driver.find_element(By.XPATH, '//*[@id=\"onetrust-accept-btn-handler\"]')\n",
    "            boton_cookies.click()\n",
    "            time.sleep(1)  # Esperar un momento después de aceptar cookies\n",
    "            print(\"Cookies aceptadas\")\n",
    "        except Exception:\n",
    "            print(\"No se encontró el botón de cookies o ya estaba aceptado\")\n",
    "\n",
    "        # Scroll infinito gradual\n",
    "        scroll_pause_time = 0.6  # Tiempo de espera entre cada desplazamiento\n",
    "        scroll_increment = 400  # Altura de desplazamiento en píxeles\n",
    "        last_height = driver.execute_script(\"return window.scrollY\")\n",
    "\n",
    "        while True:\n",
    "            driver.execute_script(f\"window.scrollBy(0, {scroll_increment});\")\n",
    "            time.sleep(scroll_pause_time)\n",
    "            new_height = driver.execute_script(\"return window.scrollY\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "\n",
    "        # Obtener el HTML completo después del scroll\n",
    "        html_completo = driver.page_source\n",
    "\n",
    "        # Crear la sopa\n",
    "        soup = BeautifulSoup(html_completo, 'html.parser')\n",
    "\n",
    "        # Limpiar la URL para usarla como nombre de archivo\n",
    "        url_limpia = re.sub(r'[^\\w\\-_\\.]', '_', url)\n",
    "\n",
    "        # Guardar el HTML en un archivo con un nombre único\n",
    "        with open(f\"../webs/pagina_pullandbear_{url_limpia}.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(html_completo)\n",
    "\n",
    "        print(f\"HTML extraído correctamente y guardado como pagina_pullandbear_{url_limpia}.html\")\n",
    "        result = soup\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando la URL {url}: {e}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Configuración del driver\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# URLs a procesar\n",
    "listaurl = [\n",
    "    \"https://www.pullandbear.com/es/hombre/ropa/camisetas-n6323\",\n",
    "    \"https://www.pullandbear.com/es/hombre/rebajas/ropa/camisetas-y-polos-n7087\",\n",
    "    \"https://www.pullandbear.com/es/hombre/ropa/camisas-n6313\",\n",
    "    \"https://www.pullandbear.com/es/hombre/rebajas/ropa/camisas-n7088\",\n",
    "    \"https://www.pullandbear.com/es/hombre/ropa/punto-n6372\",\n",
    "    \"https://www.pullandbear.com/es/hombre/rebajas/ropa/punto-n7090\",\n",
    "    \"https://www.pullandbear.com/es/hombre/ropa/sudaderas-n6382\",\n",
    "    \"https://www.pullandbear.com/es/hombre/rebajas/ropa/sudaderas-n7089\",\n",
    "    \"https://www.pullandbear.com/es/hombre/ropa/pantalones-n6363\",\n",
    "    \"https://www.pullandbear.com/es/hombre/rebajas/ropa/pantalones-n7091\",\n",
    "    \"https://www.pullandbear.com/es/hombre/ropa/jeans-n6347\",\n",
    "    \"https://www.pullandbear.com/es/hombre/rebajas/ropa/jeans-n7818\"\n",
    "]\n",
    "\n",
    "# Inicializar listas para almacenar la información extraída\n",
    "product_names = []\n",
    "product_links = []\n",
    "image1_urls = []\n",
    "image2_urls = []\n",
    "product_prices = []\n",
    "\n",
    "# Procesar cada URL una por una\n",
    "for url in tqdm(listaurl):\n",
    "    sopa = process_url(url, driver)\n",
    "    if sopa:\n",
    "        products = sopa.find_all('legacy-product')\n",
    "        print(f\"Se han encontrado {len(products)} productos\")\n",
    "\n",
    "        for product in products:\n",
    "            # Extraer el nombre del producto\n",
    "            name = product.find('span', class_='product-name')\n",
    "            product_names.append(name.text.strip() if name else None)\n",
    "\n",
    "            # Extraer el enlace del producto\n",
    "            link = product.find('a', class_='carousel-item-container')\n",
    "            product_link = link['href'] if link and 'href' in link.attrs else None\n",
    "            product_links.append(product_link)\n",
    "\n",
    "            # Extraer URLs de imágenes\n",
    "            images = product.find_all('img', class_='image-responsive')\n",
    "            image_urls = [img['src'] for img in images if 'src' in img.attrs]\n",
    "\n",
    "            # Guardar las primeras dos imágenes si existen\n",
    "            image1_urls.append(image_urls[0] if len(image_urls) > 0 else None)\n",
    "            image2_urls.append(image_urls[1] if len(image_urls) > 1 else None)\n",
    "\n",
    "            # Extraer y transformar el precio del producto\n",
    "            price_div = product.find('div', class_='product-price--price')\n",
    "            if price_div:\n",
    "                raw_price = price_div.text.strip()  # Extraer el texto del precio\n",
    "                # Normalizar el texto eliminando caracteres no deseados\n",
    "                raw_price = raw_price.replace(\"\\xa0\", \"\").replace(\"€\", \"\").strip()  # Quitar el símbolo de moneda y espacios\n",
    "                try:\n",
    "                    # Transformar el precio al formato deseado\n",
    "                    transformed_price = float(raw_price.replace(\",\", \".\"))  # Reemplazar coma por punto\n",
    "                    product_prices.append(transformed_price)\n",
    "                except ValueError as e:\n",
    "                    print(\"ValueError:\", e)\n",
    "                    product_prices.append(None)\n",
    "            else:\n",
    "                print(\"price_div not found\")\n",
    "                product_prices.append(None)\n",
    "\n",
    "# Cerrar el driver\n",
    "driver.quit()\n",
    "\n",
    "# Crear un DataFrame con la información extraída\n",
    "data = {\n",
    "    'Product Name': product_names,\n",
    "    'url': product_links,\n",
    "    'Image 1 URL': image1_urls,\n",
    "    'Image 2 URL': image2_urls,\n",
    "    'current_price': product_prices\n",
    "\n",
    "}\n",
    "df_nuevo = pd.DataFrame(data)\n",
    "\n",
    "# Mostrar articulos antes y despues\n",
    "print(\"Articulos base:\")\n",
    "print(df_base.shape)\n",
    "print(\"Articulos actuales:\")\n",
    "print(df_nuevo.shape)\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "df_nuevo.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPROBACIÓN DE ESTADO CON LA BBDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevas URLs en df_nuevo que no están en df_base:\n",
      "35\n",
      "\n",
      "URLs en df_base que no están en df_nuevo (out of stock):\n",
      "221\n",
      "Se han guardado 0 productos con cambio de precio en 'productos_cambiaron_precio.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Añadir la columna de stock al df_base\n",
    "# Si la URL está en df_nuevo, significa que está en stock; de lo contrario, no lo está\n",
    "df_base['Stock Status'] = df_base['url'].apply(\n",
    "    lambda x: 'In Stock' if x in df_nuevo['url'].values else 'Out of Stock'\n",
    ")\n",
    "\n",
    "# Actualizar los precios en df_base si el precio en df_nuevo es diferente\n",
    "for index, row in df_base.iterrows():\n",
    "    if row['url'] in df_nuevo['url'].values:\n",
    "        # Tomar el precio de df_nuevo (current_price)\n",
    "        nuevo_precio = df_nuevo.loc[df_nuevo['url'] == row['url'], 'current_price'].values[0]\n",
    "        \n",
    "        # Comparar con el precio actual en df_base (current_price_x)\n",
    "        if row['current_price_x'] != nuevo_precio:\n",
    "            df_base.at[index, 'current_price_x'] = nuevo_precio\n",
    "\n",
    "# Nuevas URLs en df_nuevo que no están en df_base\n",
    "new_urls = df_nuevo[~df_nuevo['url'].isin(df_base['url'])]\n",
    "\n",
    "# URLs en df_base que no están en df_nuevo (para marcar como \"out of stock\")\n",
    "out_of_stock_urls = df_base[~df_base['url'].isin(df_nuevo['url'])]\n",
    "\n",
    "# Filtrar productos que cambiaron de precio\n",
    "productos_cambiados = df_base[df_base['url'].isin(df_nuevo['url'])].copy()\n",
    "\n",
    "productos_cambiados['Nuevo Precio'] = productos_cambiados['url'].apply(\n",
    "    lambda x: df_nuevo.loc[df_nuevo['url'] == x, 'current_price'].values[0] if x in df_nuevo['url'].values else None\n",
    ")\n",
    "\n",
    "# Filtrar únicamente los productos donde el precio cambió\n",
    "productos_cambiados = productos_cambiados[productos_cambiados['current_price_x'] != productos_cambiados['Nuevo Precio']]\n",
    "\n",
    "# Guardar los resultados en CSV\n",
    "productos_cambiados.to_csv('../results/productos_cambiaron_precio.csv', index=False)\n",
    "new_urls.to_csv('../results/new_urls.csv', index=False)\n",
    "out_of_stock_urls.to_csv('../results/out_of_stock_urls.csv', index=False)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Nuevas URLs en df_nuevo que no están en df_base:\")\n",
    "print(len(new_urls))\n",
    "print(\"\\nURLs en df_base que no están en df_nuevo (out of stock):\")\n",
    "print(len(out_of_stock_urls))\n",
    "print(f\"Se han guardado {len(productos_cambiados)} productos con cambio de precio en 'productos_cambiaron_precio.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapeo de las nuevas urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?it/s]C:\\Users\\alexc\\AppData\\Local\\Temp\\ipykernel_3260\\2346197099.py:69: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  script_js = soup.find(\"script\", text=re.compile(\"inditex.iParams\"))\n",
      " 11%|█▏        | 4/35 [00:12<01:52,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error procesando la URL https://www.pullandbear.com/es/sudadera-manga-corta-pb-black-label-l07590567?cS=800&pelement=631601841: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00A26FB3+25091]\n",
      "\t(No symbol) [0x009AE5D4]\n",
      "\t(No symbol) [0x0088B353]\n",
      "\t(No symbol) [0x008CF4BC]\n",
      "\t(No symbol) [0x008CF63B]\n",
      "\t(No symbol) [0x0090D8B2]\n",
      "\t(No symbol) [0x008F1F24]\n",
      "\t(No symbol) [0x0090B46E]\n",
      "\t(No symbol) [0x008F1C76]\n",
      "\t(No symbol) [0x008C3185]\n",
      "\t(No symbol) [0x008C430D]\n",
      "\tGetHandleVerifier [0x00D1D5B3+3131395]\n",
      "\tGetHandleVerifier [0x00D2DDA4+3198964]\n",
      "\tGetHandleVerifier [0x00D28CC2+3178258]\n",
      "\tGetHandleVerifier [0x00AC3290+664800]\n",
      "\t(No symbol) [0x009B744D]\n",
      "\t(No symbol) [0x009B4798]\n",
      "\t(No symbol) [0x009B4936]\n",
      "\t(No symbol) [0x009A7030]\n",
      "\tBaseThreadInitThunk [0x769A7BA9+25]\n",
      "\tRtlInitializeExceptionChain [0x77CEC0CB+107]\n",
      "\tRtlClearBits [0x77CEC04F+191]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 23/35 [00:49<00:34,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error procesando la URL https://www.pullandbear.com/es/pantalon-cargo-lavado-l07678525?cS=802&pelement=662006280: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00A26FB3+25091]\n",
      "\t(No symbol) [0x009AE5D4]\n",
      "\t(No symbol) [0x0088B353]\n",
      "\t(No symbol) [0x008CF4BC]\n",
      "\t(No symbol) [0x008CF63B]\n",
      "\t(No symbol) [0x0090D8B2]\n",
      "\t(No symbol) [0x008F1F24]\n",
      "\t(No symbol) [0x0090B46E]\n",
      "\t(No symbol) [0x008F1C76]\n",
      "\t(No symbol) [0x008C3185]\n",
      "\t(No symbol) [0x008C430D]\n",
      "\tGetHandleVerifier [0x00D1D5B3+3131395]\n",
      "\tGetHandleVerifier [0x00D2DDA4+3198964]\n",
      "\tGetHandleVerifier [0x00D28CC2+3178258]\n",
      "\tGetHandleVerifier [0x00AC3290+664800]\n",
      "\t(No symbol) [0x009B744D]\n",
      "\t(No symbol) [0x009B4798]\n",
      "\t(No symbol) [0x009B4936]\n",
      "\t(No symbol) [0x009A7030]\n",
      "\tBaseThreadInitThunk [0x769A7BA9+25]\n",
      "\tRtlInitializeExceptionChain [0x77CEC0CB+107]\n",
      "\tRtlClearBits [0x77CEC04F+191]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:09<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articulos de tras actualización:\n",
      "(950, 18)\n",
      "Se guardaron 43 filas descartadas en 'descartes.csv'.\n",
      "Articulos sin duplicados:\n",
      "(907, 18)\n"
     ]
    }
   ],
   "source": [
    "# Función para extraer el valor numérico de los precios\n",
    "def extract_numeric_price(price_text):\n",
    "    if price_text:\n",
    "        return float(re.sub(r'[^\\d,]', '', price_text).replace(',', '.'))\n",
    "    return None\n",
    "\n",
    "# Configuración de Selenium\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Función para procesar una URL individual\n",
    "def process_url(row):\n",
    "    url = row['url']\n",
    "    result = {\n",
    "        \"url\": url,\n",
    "        \"description\": None,\n",
    "        \"sale_price\": None,\n",
    "        \"old_price\": None,\n",
    "        \"original_price\": None,\n",
    "        \"current_price\": None,\n",
    "        \"color\": None,\n",
    "        \"image_url\": None,\n",
    "        \"mpn\": None,\n",
    "        \"reference_code\": None,\n",
    "        \"category_id\": None,\n",
    "        \"Stock Status\":\"In stock\"\n",
    "    }\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        # Esperar hasta que el color esté presente (máximo 10 segundos)\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, '.product-card-color-selector--popup-colors-color-name'))\n",
    "        )\n",
    "        # Espera adicional para asegurarse de que la página está completamente cargada\n",
    "        WebDriverWait(driver, 3).until(\n",
    "            lambda x: x.execute_script(\"return document.readyState === 'complete'\")\n",
    "        )\n",
    "\n",
    "        # Extraer contenido HTML\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        # Extraer precios\n",
    "        sale_price = soup.select_one('.prices .sale .number')\n",
    "        old_price = soup.select_one('.prices .price-old .number')\n",
    "        original_price = soup.select_one('.prices .price-original .number')\n",
    "        single_price = soup.select_one('.price .number.hansolo')\n",
    "\n",
    "        result['sale_price'] = extract_numeric_price(sale_price.text.strip()) if sale_price else None\n",
    "        result['old_price'] = extract_numeric_price(old_price.text.strip()) if old_price else None\n",
    "        result['original_price'] = extract_numeric_price(original_price.text.strip()) if original_price else None\n",
    "        result['current_price'] = extract_numeric_price(single_price.text.strip()) if single_price else min(\n",
    "            filter(None, [result['sale_price'], result['old_price'], result['original_price']]), default=None\n",
    "        )\n",
    "\n",
    "        # Extraer color\n",
    "        color_element = soup.select_one('.product-card-color-selector--popup-colors-color-name')\n",
    "        result['color'] = color_element.text.strip() if color_element else None\n",
    "\n",
    "        # Extraer descripción y MPN\n",
    "        json_ld = soup.find(\"script\", type=\"application/ld+json\")\n",
    "        if json_ld:\n",
    "            product_data = json.loads(json_ld.string)\n",
    "            result['description'] = product_data.get(\"description\", None)\n",
    "            result['mpn'] = product_data.get(\"mpn\", None)\n",
    "\n",
    "        # Extraer datos del script JavaScript\n",
    "        script_js = soup.find(\"script\", text=re.compile(\"inditex.iParams\"))\n",
    "        if script_js:\n",
    "            script_text = script_js.string\n",
    "            mfname_match = re.search(r'mfname\":\\[\"(\\d+)\"\\]', script_text)\n",
    "            category_id_match = re.search(r'categoryId\":\\[\"(\\d+)\"\\]', script_text)\n",
    "\n",
    "            result['reference_code'] = mfname_match.group(1) if mfname_match else None\n",
    "            result['category_id'] = category_id_match.group(1) if category_id_match else None\n",
    "\n",
    "        # Extraer URL de la imagen principal solo si no existe ya\n",
    "        if not result['image_url']:\n",
    "            image_element = soup.select_one('img')\n",
    "            result['image_url'] = image_element['src'] if image_element and 'src' in image_element.attrs else None\n",
    "\n",
    "        # Verificar datos faltantes\n",
    "        if not result['color']:\n",
    "            result['missing_data'] = True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando la URL {url}: {e}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Inicializar el navegador y procesar URLs en paralelo\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "rows = new_urls.to_dict('records')\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    results = list(tqdm(executor.map(process_url, rows), total=len(rows)))\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Crear DataFrames para resultados exitosos y con datos faltantes\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results=pd.merge(df_results,new_urls,on='url', how='inner')\n",
    "\n",
    "# Unir los DataFrames utilizando la columna 'url'\n",
    "df_successful = pd.concat([df_base, df_results], axis=0, ignore_index=True)\n",
    "\n",
    "# Columnas clave para identificar otros duplicados\n",
    "columnas_clave = ['current_price_y','current_price_x','color','image_url','mpn','reference_code','category_id']\n",
    "\n",
    "# Crear un DataFrame con los duplicados eliminados\n",
    "df_sin_duplicados = df_successful.drop_duplicates(subset=columnas_clave, keep='first')\n",
    "\n",
    "# Identificar las filas descartadas como la diferencia entre los originales y los sin duplicados\n",
    "descartes = df_successful.loc[~df_successful.index.isin(df_sin_duplicados.index)]\n",
    "\n",
    "# Guardar los descartes en un archivo CSV\n",
    "descartes.to_csv('../results/articulos_descartados.csv', index=False)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Articulos de tras actualización:\")\n",
    "print(df_successful.shape)\n",
    "print(f\"Se guardaron {len(descartes)} filas descartadas en 'descartes.csv'.\")\n",
    "print(\"Articulos sin duplicados:\")\n",
    "print(df_sin_duplicados.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMOGENEIZAR LOS DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\AppData\\Local\\Temp\\ipykernel_3260\\3632465851.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sin_duplicados['color_homogeneizado'] = df_sin_duplicados['color'].apply(homogeneizar_color)\n"
     ]
    }
   ],
   "source": [
    "# Función para homogeneizar colores\n",
    "def homogeneizar_color(color):\n",
    "    color = str(color).lower()  # Convertir a minúsculas para uniformidad\n",
    "    if any(c in color for c in ['blanco', 'hueso', 'crema','crudo']):\n",
    "        return 'Blanco'\n",
    "    elif any(c in color for c in ['negro', 'vigoré oscuro']):\n",
    "        return 'Negro'\n",
    "    elif any(c in color for c in ['gris', 'vigoré', 'plomo']):\n",
    "        return 'Gris'\n",
    "    elif any(c in color for c in ['azul claro', 'azul flúor', 'indigo', 'celeste']):\n",
    "        return 'Azul claro'\n",
    "    elif any(c in color for c in ['azul', 'marino', 'indigo']):\n",
    "        return 'Azul'\n",
    "    elif any(c in color for c in ['verde', 'menta', 'lima', 'botella', 'pistacho']):\n",
    "        return 'Verde'\n",
    "    elif any(c in color for c in ['beige', 'caqui', 'hielo', 'natural', 'piedra', 'tostado','arena']):\n",
    "        return 'Marrón claro'\n",
    "    elif any(c in color for c in ['marrón', 'caramelo', 'tabaco', 'chocolate', 'topo', 'tierra', 'coñac']):\n",
    "        return 'Marrón'\n",
    "    elif any(c in color for c in ['rojo', 'granate', 'coral', 'burgundy', 'teja', 'burdeos']):\n",
    "        return 'Rojo'\n",
    "    elif any(c in color for c in ['rosa', 'lila', 'berenjena', 'morado', 'malva']):\n",
    "        return 'Rosa/Púrpura'\n",
    "    elif any(c in color for c in ['amarillo', 'mostaza']):\n",
    "        return 'Amarillo'\n",
    "    elif any(c in color for c in ['naranja']):\n",
    "        return 'Naranja'\n",
    "    elif any(c in color for c in ['varios', 'rayas']):\n",
    "        return 'Multicolor'\n",
    "    else:\n",
    "        return 'Otros'\n",
    "\n",
    "# Crear una nueva columna con el color homogeneizado\n",
    "df_sin_duplicados['color_homogeneizado'] = df_sin_duplicados['color'].apply(homogeneizar_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATEGORÍA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\AppData\\Local\\Temp\\ipykernel_3260\\1222395398.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sin_duplicados['Categoria'] = df_sin_duplicados['Product Name'].apply(categorizar_ropa)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Sudadera caballo Ford Bronco</td>\n",
       "      <td>Sudadera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>Sudadera Arcane Jinx</td>\n",
       "      <td>Sudadera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Sudadera capucha Bad Ideas</td>\n",
       "      <td>Sudadera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Jersey cuello cremallera</td>\n",
       "      <td>Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Camiseta negra Sakamoto</td>\n",
       "      <td>Camiseta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>Jeans standard cargo</td>\n",
       "      <td>Pantalón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Chaqueta chándal retro STWD</td>\n",
       "      <td>Otros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Pantalón jogger piqué</td>\n",
       "      <td>Pantalón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>Sudadera capucha flor</td>\n",
       "      <td>Sudadera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Jeans loose fit</td>\n",
       "      <td>Pantalón</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Product Name Categoria\n",
       "396  Sudadera caballo Ford Bronco  Sudadera\n",
       "825          Sudadera Arcane Jinx  Sudadera\n",
       "429    Sudadera capucha Bad Ideas  Sudadera\n",
       "247      Jersey cuello cremallera    Jersey\n",
       "1         Camiseta negra Sakamoto  Camiseta\n",
       "881          Jeans standard cargo  Pantalón\n",
       "427   Chaqueta chándal retro STWD     Otros\n",
       "505         Pantalón jogger piqué  Pantalón\n",
       "822         Sudadera capucha flor  Sudadera\n",
       "873               Jeans loose fit  Pantalón"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorizar_ropa(product_name):\n",
    "    product_name = str(product_name).lower()  # Convertir a minúsculas para uniformidad\n",
    "    if any(p in product_name for p in ['pack']):\n",
    "        return 'Pack'\n",
    "    if any(p in product_name for p in ['camiseta','sudadera manga corta']):\n",
    "        return 'Camiseta'\n",
    "    if any(p in product_name for p in ['sudadera', 'hoodie']):\n",
    "        return 'Sudadera'\n",
    "    if any(p in product_name for p in ['polo']):\n",
    "        return 'Polo'\n",
    "    elif any(p in product_name for p in ['sobrecamisa']):\n",
    "        return 'Sobrecamisa'\n",
    "    elif any(p in product_name for p in ['camisa']):\n",
    "        return 'Camisa'\n",
    "    elif any(p in product_name for p in ['pantalón', 'pantalones', 'jeans', 'vaqueros']):\n",
    "        return 'Pantalón'\n",
    "    elif any(p in product_name for p in ['jersey']):\n",
    "        return 'Jersey'\n",
    "    elif any(p in product_name for p in ['zapato', 'botas', 'sandalias', 'calzado']):\n",
    "        return 'Calzado'\n",
    "    elif any(p in product_name for p in ['accesorio', 'gorra', 'bufanda', 'cinturón', 'bolso']):\n",
    "        return 'Accesorio'\n",
    "    else:\n",
    "        return 'Otros'\n",
    "\n",
    "# Crear una nueva columna con la categoría de la prenda\n",
    "df_sin_duplicados['Categoria'] = df_sin_duplicados['Product Name'].apply(categorizar_ropa)\n",
    "\n",
    "# Mostrar las primeras filas para comprobar\n",
    "df_sin_duplicados[['Product Name', 'Categoria']].sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTROLAR URLs FALTANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar \"out of stock\" a la columna 'Stock Status' donde 'image_url' sea vacío o nulo\n",
    "df_sin_duplicados.loc[(df_sin_duplicados['image_url'].isna()) | (df_sin_duplicados['image_url'] == ''), 'Stock Status'] = 'Out of Stock'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUARDAR CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los pantalones\n",
    "Modelos_enteros = df_sin_duplicados[    (df_sin_duplicados['Categoria'] == 'Pantalón') & (df_sin_duplicados['Stock Status'] == 'In Stock')]  # Cambia 'tipo_prenda' y 'pantalón' si tienen otros nombres\n",
    "\n",
    "# Guardar el nuevo DataFrame con pantalones en un archivo CSV\n",
    "Modelos_enteros.to_csv('../results/Modelos_enteros.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los cambios en un archivo nuevo si lo necesitas\n",
    "df_sin_duplicados.to_csv('../results/all_products_info_with_categories.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
